{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9b0d31",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import albumentations as A\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from transformers import SegformerForSemanticSegmentation\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "class Config:\n",
    "    # Update these paths if your Kaggle directory structure is different\n",
    "    ROOT = \"/kaggle/input/terra-seg-rugged-terrain-segmentation/offroad-seg-kaggle\"\n",
    "    TRAIN_IMG = os.path.join(ROOT, \"train_images\")\n",
    "    TRAIN_MSK = os.path.join(ROOT, \"train_masks\")\n",
    "    TEST_IMG  = os.path.join(ROOT, \"test_images_padded\")\n",
    "    \n",
    "    IMG_SIZE = (512, 512)\n",
    "    VAL_SPLIT = 0.15        \n",
    "    BATCH_SIZE = 4          \n",
    "    ACCUMULATION_STEPS = 4  \n",
    "    NUM_WORKERS = 4         \n",
    "    LR = 6e-5               \n",
    "    EPOCHS = 30             \n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # 'nvidia/mit-b5' is accurate but heavy. \n",
    "    # If you hit OOM (Out Of Memory), switch to 'nvidia/mit-b2' or 'nvidia/mit-b1'.\n",
    "    MODEL_CHECKPOINT = \"nvidia/mit-b5\" \n",
    "    SAVE_PATH = \"best_segformer_avl.pth\"\n",
    "\n",
    "# ==========================================\n",
    "# 2. AVL: ADAPTIVE VALIDATION LOGIC\n",
    "# ==========================================\n",
    "class AVLTracker:\n",
    "    \"\"\"\n",
    "    Adaptive Validation Logic.\n",
    "    Tracks Exponential Moving Average (EMA) of IoU to prevent saving models \n",
    "    based on 'lucky' spikes in validation performance.\n",
    "    \"\"\"\n",
    "    def __init__(self, window_size=3):\n",
    "        self.window_size = window_size\n",
    "        self.history = []\n",
    "        self.best_ema_iou = 0.0\n",
    "\n",
    "    def update(self, current_iou):\n",
    "        self.history.append(current_iou)\n",
    "        if len(self.history) > self.window_size:\n",
    "            self.history.pop(0)\n",
    "        \n",
    "        # Calculate Moving Average\n",
    "        ema_iou = sum(self.history) / len(self.history)\n",
    "        \n",
    "        is_best = False\n",
    "        if ema_iou > self.best_ema_iou:\n",
    "            self.best_ema_iou = ema_iou\n",
    "            is_best = True\n",
    "        \n",
    "        return ema_iou, is_best\n",
    "\n",
    "# ==========================================\n",
    "# 3. TVERSKY LOSS\n",
    "# ==========================================\n",
    "class TverskyLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.3, beta=0.7, smooth=1e-6):\n",
    "        \"\"\"\n",
    "        Tversky Loss Implementation.\n",
    "        \n",
    "        Args:\n",
    "            alpha (float): Weight for False Positives.\n",
    "            beta (float):  Weight for False Negatives. \n",
    "                           If beta > alpha, we penalize missing the target more (Recall focused).\n",
    "            smooth (float): Smoothing factor for numerical stability.\n",
    "        \"\"\"\n",
    "        super(TverskyLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        # 1. Resize logits to match target size (upsampling predictions)\n",
    "        # This preserves the detail in the ground truth masks.\n",
    "        if logits.shape[-2:] != targets.shape[-2:]:\n",
    "            logits = F.interpolate(logits, size=targets.shape[-2:], mode='bilinear', align_corners=False)\n",
    "            \n",
    "        # 2. Sigmoid activation\n",
    "        probs = torch.sigmoid(logits)\n",
    "        \n",
    "        # 3. Flatten\n",
    "        probs = probs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        # 4. Calculate TP, FP, FN\n",
    "        TP = (probs * targets).sum()\n",
    "        FP = ((1 - targets) * probs).sum()\n",
    "        FN = (targets * (1 - probs)).sum()\n",
    "        \n",
    "        # 5. Tversky Index\n",
    "        tversky_index = (TP + self.smooth) / (TP + self.alpha * FP + self.beta * FN + self.smooth)\n",
    "        \n",
    "        return 1 - tversky_index\n",
    "\n",
    "# ==========================================\n",
    "# 4. DATASET\n",
    "# ==========================================\n",
    "class TerrainDataset(Dataset):\n",
    "    def __init__(self, img_dir, mask_dir=None, file_list=None, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        if file_list is not None:\n",
    "            self.images = file_list\n",
    "        else:\n",
    "            self.images = sorted([f for f in os.listdir(img_dir) if f.lower().endswith(('.png', '.jpg'))])\n",
    "\n",
    "    def __len__(self): return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.images[idx]\n",
    "        image_path = os.path.join(self.img_dir, img_name)\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.mask_dir:\n",
    "            mask_path = os.path.join(self.mask_dir, img_name)\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            mask = (mask > 127).astype(np.float32)\n",
    "            \n",
    "            if self.transform:\n",
    "                aug = self.transform(image=image, mask=mask)\n",
    "                image = aug['image']\n",
    "                mask = aug['mask']\n",
    "            \n",
    "            return image, mask.unsqueeze(0)\n",
    "        \n",
    "        h, w = image.shape[:2]\n",
    "        if self.transform:\n",
    "            aug = self.transform(image=image)\n",
    "            image = aug['image']\n",
    "            \n",
    "        return image, img_name, (h, w)\n",
    "\n",
    "# Helper for IoU Calculation\n",
    "def calculate_iou(preds, targets):\n",
    "    if preds.shape[-2:] != targets.shape[-2:]:\n",
    "        preds = F.interpolate(preds, size=targets.shape[-2:], mode='bilinear', align_corners=False)\n",
    "        \n",
    "    preds = (torch.sigmoid(preds) > 0.5).float()\n",
    "    intersection = (preds * targets).sum()\n",
    "    union = (preds + targets).clamp(0, 1).sum()\n",
    "    return (intersection / (union + 1e-7)).item()\n",
    "\n",
    "# ==========================================\n",
    "# 5. TRAINING LOOP\n",
    "# ==========================================\n",
    "def train_model():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    # 5.1 Data Prep\n",
    "    all_images = sorted([f for f in os.listdir(Config.TRAIN_IMG) if f.lower().endswith(('.png', '.jpg'))])\n",
    "    train_files, val_files = train_test_split(all_images, test_size=Config.VAL_SPLIT, random_state=42)\n",
    "\n",
    "    transforms = {\n",
    "        \"train\": A.Compose([\n",
    "            A.Resize(Config.IMG_SIZE[0], Config.IMG_SIZE[1]),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.RandomBrightnessContrast(p=0.2),\n",
    "            A.Normalize(),\n",
    "            ToTensorV2()\n",
    "        ]),\n",
    "        \"val\": A.Compose([\n",
    "            A.Resize(Config.IMG_SIZE[0], Config.IMG_SIZE[1]),\n",
    "            A.Normalize(),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    }\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        TerrainDataset(Config.TRAIN_IMG, Config.TRAIN_MSK, train_files, transforms[\"train\"]), \n",
    "        batch_size=Config.BATCH_SIZE, shuffle=True, num_workers=Config.NUM_WORKERS, pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        TerrainDataset(Config.TRAIN_IMG, Config.TRAIN_MSK, val_files, transforms[\"val\"]), \n",
    "        batch_size=Config.BATCH_SIZE, num_workers=Config.NUM_WORKERS, pin_memory=True\n",
    "    )\n",
    "\n",
    "    # 5.2 Model Setup\n",
    "    print(f\"ðŸ—ï¸ Loading Model: {Config.MODEL_CHECKPOINT}...\")\n",
    "    model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "        Config.MODEL_CHECKPOINT, \n",
    "        num_labels=1, \n",
    "        ignore_mismatched_sizes=True\n",
    "    ).to(Config.DEVICE)\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=Config.LR, weight_decay=1e-2)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3) \n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    # 5.3 Loss Definition (USING TVERSKY)\n",
    "    # Alpha=0.3, Beta=0.7 favors Recall (penalizes missing obstacles more than false alarms)\n",
    "    criterion = TverskyLoss(alpha=0.3, beta=0.7)\n",
    "    \n",
    "    # AVL Initialize\n",
    "    avl = AVLTracker(window_size=3)\n",
    "\n",
    "    print(f\"ðŸš€ Training Started with Tversky Loss...\")\n",
    "\n",
    "    for epoch in range(Config.EPOCHS):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{Config.EPOCHS} [TRAIN]\")\n",
    "        \n",
    "        for i, (imgs, msks) in enumerate(pbar):\n",
    "            imgs, msks = imgs.to(Config.DEVICE), msks.to(Config.DEVICE)\n",
    "            \n",
    "            with autocast():\n",
    "                outputs = model(imgs)\n",
    "                # Note: outputs.logits are typically 1/4th size, criterion handles interpolation\n",
    "                loss = criterion(outputs.logits, msks) / Config.ACCUMULATION_STEPS\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            if (i + 1) % Config.ACCUMULATION_STEPS == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            train_loss += loss.item() * Config.ACCUMULATION_STEPS\n",
    "            pbar.set_postfix(loss=train_loss/(i+1))\n",
    "\n",
    "        # VALIDATION\n",
    "        model.eval()\n",
    "        val_iou = 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, msks in val_loader:\n",
    "                imgs, msks = imgs.to(Config.DEVICE), msks.to(Config.DEVICE)\n",
    "                val_iou += calculate_iou(model(imgs).logits, msks)\n",
    "        \n",
    "        avg_iou = val_iou / len(val_loader)\n",
    "        \n",
    "        # AVL LOGIC CHECK\n",
    "        ema_iou, is_best = avl.update(avg_iou)\n",
    "        scheduler.step(ema_iou)\n",
    "        \n",
    "        print(f\"ðŸ“Š Epoch {epoch+1} | Raw IoU: {avg_iou:.4f} | AVL (EMA) IoU: {ema_iou:.4f}\")\n",
    "\n",
    "        if is_best:\n",
    "            torch.save(model.state_dict(), Config.SAVE_PATH)\n",
    "            print(f\"â­ AVL System: New stable high score detected. Model saved!\")\n",
    "\n",
    "# ==========================================\n",
    "# 6. INFERENCE\n",
    "# ==========================================\n",
    "def run_inference():\n",
    "    print(\"ðŸ”® Starting Inference...\")\n",
    "    model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "        Config.MODEL_CHECKPOINT, \n",
    "        num_labels=1, \n",
    "        ignore_mismatched_sizes=True\n",
    "    ).to(Config.DEVICE)\n",
    "    \n",
    "    model.load_state_dict(torch.load(Config.SAVE_PATH))\n",
    "    model.eval()\n",
    "\n",
    "    test_ds = TerrainDataset(Config.TEST_IMG, transform=A.Compose([\n",
    "        A.Resize(Config.IMG_SIZE[0], Config.IMG_SIZE[1]), \n",
    "        A.Normalize(), \n",
    "        ToTensorV2()\n",
    "    ]))\n",
    "    loader = DataLoader(test_ds, batch_size=1)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Run-Length Encoding Helper\n",
    "    def rle(m):\n",
    "        p = m.T.flatten(); p = np.concatenate([[0], p, [0]])\n",
    "        r = np.where(p[1:] != p[:-1])[0] + 1; r[1::2] -= r[::2]\n",
    "        return ' '.join(str(x) for x in r)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img, name, (h, w) in tqdm(loader, desc=\"Inference\"):\n",
    "            logits = model(img.to(Config.DEVICE)).logits\n",
    "            # Resize logits to original image size\n",
    "            logits = F.interpolate(logits, size=(h.item(), w.item()), mode='bilinear')\n",
    "            mask = (torch.sigmoid(logits) > 0.5).cpu().numpy()[0, 0].astype(np.uint8)\n",
    "            results.append({\"image_id\": int(os.path.splitext(name[0])[0]), \"encoded_pixels\": rle(mask)})\n",
    "\n",
    "    pd.DataFrame(results).sort_values(\"image_id\").to_csv(\"submission.csv\", index=False)\n",
    "    print(\"âœ¨ submission.csv saved via AVL optimization & Tversky Loss!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_model()\n",
    "    run_inference()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
