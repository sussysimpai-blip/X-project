{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab98b922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'metric': {'instance': '134.209.146.26:9100'}, 'value': [1770638972.341, '3.4562500000053404']}, {'metric': {'instance': 'SaltClient:9100'}, 'value': [1770638972.341, '1.4112676408270772']}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def query_prometheus(prom_ql):\n",
    "    # Base URL for Prometheus (usually port 9090)\n",
    "    # Replace with your actual Prometheus IP\n",
    "    URL = \"http://167.71.227.138:9090/api/v1/query\"\n",
    "    \n",
    "    params = {\n",
    "        'query': prom_ql\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(URL, params=params, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            results = response.json()['data']['result']\n",
    "            return results\n",
    "        else:\n",
    "            return f\"Error: {response.status_code} - {response.text}\"\n",
    "    except Exception as e:\n",
    "        return f\"Connection Failed: {str(e)}\"\n",
    "\n",
    "# Example: Get average CPU usage over the last 5 minutes\n",
    "cpu_query = '100 - (avg by (instance) (rate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)'\n",
    "data = query_prometheus(cpu_query)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba788e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'Python 3 (ipykernel)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. Unable to get resolved server information for google.colab:colab:ead87635-8986-460b-9b65-1d10c964b7b7"
     ]
    }
   ],
   "source": [
    "pip install langchain_huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8606237f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'Python 3 (ipykernel)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. Unable to get resolved server information for google.colab:colab:ead87635-8986-460b-9b65-1d10c964b7b7"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "\n",
    "llm_model = HuggingFaceEndpoint(\n",
    "    repo_id=\"Qwen/Qwen2.5-7B-Instruct\",\n",
    "    huggingfacehub_api_token=\"\",\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=128,\n",
    ")\n",
    "\n",
    "\n",
    "llm = ChatHuggingFace(llm=llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b504f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "\n",
    "def send_to_alertmanager(summary, description):\n",
    "    # The Alertmanager API endpoint\n",
    "    URL = \"http://167.71.227.138:9093/api/v2/alerts\"\n",
    "    \n",
    "    # Standard Alertmanager JSON format\n",
    "    payload = [{\n",
    "        \"labels\": {\n",
    "            \"alertname\": \"AIAgentResponse\",\n",
    "            \"severity\": \"info\",\n",
    "            \"source\": \"ai-bot\"\n",
    "        },\n",
    "        \"annotations\": {\n",
    "            \"summary\": summary,\n",
    "            \"description\": description\n",
    "        },\n",
    "        \"startsAt\": datetime.datetime.now().isoformat() + \"Z\"\n",
    "    }]\n",
    "\n",
    "    try:\n",
    "        response = requests.post(URL, json=payload)\n",
    "        if response.status_code == 200:\n",
    "            return \"Success: Message routed through Alertmanager.\"\n",
    "        else:\n",
    "            return f\"Error: {response.status_code} - {response.text}\"\n",
    "    except Exception as e:\n",
    "        return f\"Connection Failed: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c8da36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integration: LLM Analysis of Prometheus Data -> AlertManager\n",
    "\n",
    "if 'data' in locals() and data:\n",
    "    # 1. Prepare the prompt with the data from Cell 1\n",
    "    # Note: The query was for CPU idle time. \n",
    "    # High Idle (near 100) = Low Usage. Low Idle = High Usage.\n",
    "    prompt = f\"\"\"\n",
    "    Analyze the following Prometheus metrics for CPU Mode=\"idle\".\n",
    "    Data: {data}\n",
    "    \n",
    "    Interpret the values:\n",
    "    - Only look at the 'value' field. The second element in the list is the percentage.\n",
    "    - Since this is 'idle' mode: \n",
    "      - Value near 0 means the CPU is free (Good/Low Load).\n",
    "      - Value near 100 means the CPU is busy (High Load).\n",
    "    \n",
    "    Provide a concise summary of the health of the instances.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Sending prompt to LLM...\")\n",
    "    try:\n",
    "        # 2. Invoke LLM (defined in Cell 2)\n",
    "        response = llm.invoke(prompt)\n",
    "        ai_analysis = response.content\n",
    "        print(f\"LLM Analysis:\\n{ai_analysis}\\n\")\n",
    "        \n",
    "        # 3. Send to Alertmanager (defined in Cell 3)\n",
    "        print(\"Routing to Alertmanager...\")\n",
    "        alert_status = send_to_alertmanager(\n",
    "            summary=\"AI Analysis of CPU Metrics\", \n",
    "            description=ai_analysis\n",
    "        )\n",
    "        print(alert_status)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during AI processing: {e}\")\n",
    "else:\n",
    "    print(\"No data found. Please run the first cell to query Prometheus.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
